{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n",
    "sys.path.append('../input/rangerdeeplearningoptimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import copy\n",
    "import yaml\n",
    "import random\n",
    "import shutil\n",
    "import typing as tp\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.cuda import amp\n",
    "\n",
    "import timm\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import pytorch_pfn_extras as ppe\n",
    "from pytorch_pfn_extras.config import Config\n",
    "from pytorch_pfn_extras.training import extensions as ppe_exts, triggers as ppe_triggers\n",
    "\n",
    "from ranger.ranger2020 import Ranger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "new_date = str(datetime.datetime.now()+datetime.timedelta(hours=9))[:-16].replace('-',\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021_08_18'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = \"../input/seti-breakthrough-listen/train\"\n",
    "TEST = \"../input/seti-breakthrough-listen/test\"\n",
    "\n",
    "model = 'tf_efficientnet_b6_ns'\n",
    "\n",
    "version = 1\n",
    "TMP = f\"./{model}_new_pretrained_v{version}/\"\n",
    "# TMP = \"./tmp/tf_efficientnet_b2_ns_Ranger_amp_pseudo_fintune_512to640/\"\n",
    "if not os.path.exists(TMP):\n",
    "    os.makedirs(TMP)\n",
    "\n",
    "RANDAM_SEED = 42\n",
    "CLASSES = [\n",
    "    \"target\",\n",
    "]\n",
    "N_CLASSES = len(CLASSES)\n",
    "FOLDS = [0, 1, 2, 3, 4]\n",
    "N_FOLDS = len(FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./5folds_split_new.csv\")\n",
    "smpl_sub = pd.read_csv(\"../input/seti-breakthrough-listen/sample_submission.csv\")\n",
    "#df_test_pesudo = pd.read_csv(\"./submission_seti_9914.csv\")\n",
    "#df_test_pesudo['fold'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.groupby(\"fold\").agg(total=(\"id\", len), pos=(\"target\", sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test_pesudo['target'] = df_test_pesudo['target']/2.8214260184044444"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tobin(df, th):\n",
    "    df[df > th] = 1.0\n",
    "    df[df <= th] = 0.0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test_pesudo['target'] = tobin(df_test_pesudo['target'] , 0.85)\n",
    "#df_test_pesudo['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class enetv2(nn.Module):\n",
    "    def __init__(self, backbone, in_channels, out_dim, pretrained=True):\n",
    "        super(enetv2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels,\n",
    "                               6,\n",
    "                               3,\n",
    "                               stride=1,\n",
    "                               padding=1,\n",
    "                               bias=False)\n",
    "        self.conv2 = nn.Conv2d(6, 12, 3, stride=1, padding=1, bias=False)\n",
    "        self.conv3 = nn.Conv2d(12, 36, 3, stride=1, padding=1, bias=False)\n",
    "        self.mybn1 = nn.BatchNorm2d(6)\n",
    "        self.mybn2 = nn.BatchNorm2d(12)\n",
    "        self.mybn3 = nn.BatchNorm2d(36)\n",
    "\n",
    "        self.enet = timm.create_model(backbone,\n",
    "                                      pretrained=pretrained,\n",
    "                                      in_chans=in_channels)\n",
    "        self.enet.conv_stem.weight = nn.Parameter(\n",
    "            self.enet.conv_stem.weight.repeat(1, 36, 1, 1))\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.enet.blocks[5] = nn.Identity()\n",
    "        self.enet.blocks[6] = nn.Sequential(\n",
    "            nn.Conv2d(self.enet.blocks[4][2].conv_pwl.out_channels,\n",
    "                      self.enet.conv_head.in_channels, 1),\n",
    "            nn.BatchNorm2d(self.enet.conv_head.in_channels),\n",
    "            nn.ReLU6(),\n",
    "        )\n",
    "        self.myfc = nn.Linear(self.enet.classifier.in_features, out_dim)\n",
    "        self.enet.classifier = nn.Identity()\n",
    "\n",
    "    def extract(self, x):\n",
    "        x = F.relu6(self.mybn1(self.conv1(x)))\n",
    "        x = F.relu6(self.mybn2(self.conv2(x)))\n",
    "        x = F.relu6(self.mybn3(self.conv3(x)))\n",
    "        x = self.enet(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.extract(x)\n",
    "        x = self.myfc(self.dropout(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicImageModel(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self, base_name: str, dims_head: tp.List[int],\n",
    "        pretrained=False, in_channels: int=3\n",
    "    ):\n",
    "        \"\"\"Initialize\"\"\"\n",
    "        self.base_name = base_name\n",
    "        super(BasicImageModel, self).__init__()\n",
    "        \n",
    "        # # prepare backbone\n",
    "        if hasattr(timm.models, base_name):\n",
    "            base_model = timm.create_model(\n",
    "                base_name, num_classes=0, pretrained=pretrained, in_chans=in_channels)\n",
    "            in_features = base_model.num_features\n",
    "            print(\"load imagenet pretrained:\", pretrained)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.backbone = base_model\n",
    "        print(f\"{base_name}: {in_features}\")\n",
    "        \n",
    "        # # prepare head clasifier\n",
    "        if dims_head[0] is None:\n",
    "            dims_head[0] = in_features\n",
    "\n",
    "        layers_list = []\n",
    "        for i in range(len(dims_head) - 2):\n",
    "            in_dim, out_dim = dims_head[i: i + 2]\n",
    "            layers_list.extend([\n",
    "                nn.Linear(in_dim, out_dim),\n",
    "                nn.ReLU(), nn.Dropout(0.5),])\n",
    "        layers_list.append(\n",
    "            nn.Linear(dims_head[-2], dims_head[-1]))\n",
    "        self.head_cls = nn.Sequential(*layers_list)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward\"\"\"\n",
    "        h = self.backbone(x)\n",
    "        h = self.head_cls(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "FilePath = tp.Union[str, Path]\n",
    "Label = tp.Union[int, float, np.ndarray]\n",
    "\n",
    "\n",
    "class SetiSimpleDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset using 6 channels by stacking them along time-axis\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    paths : tp.Sequence[FilePath]\n",
    "        Sequence of path to cadence snippet file\n",
    "    labels : tp.Sequence[Label]\n",
    "        Sequence of label for cadence snippet file\n",
    "    transform: albumentations.Compose\n",
    "        composed data augmentations for data\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        paths: tp.Sequence[FilePath],\n",
    "        labels: tp.Sequence[Label],\n",
    "        transform: A.Compose,\n",
    "    ):\n",
    "        \"\"\"Initialize\"\"\"\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return num of cadence snippets\"\"\"\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        \"\"\"Return transformed image and label for given index.\"\"\"\n",
    "        path, label = self.paths[index], self.labels[index]\n",
    "        img = self._read_cadence_array(path)\n",
    "        img = self.transform(image=img)[\"image\"]\n",
    "        return {\"image\": img, \"target\": label}\n",
    "\n",
    "    def _read_cadence_array(self, path: Path):\n",
    "        \"\"\"Read cadence file and reshape\"\"\"\n",
    "        img = np.load(path)  # shape: (6, 273, 256)\n",
    "        img = np.vstack(img)  # shape: (1638, 256)\n",
    "        img = img.transpose(1, 0)  # shape: (256, 1638)\n",
    "        img = img.astype(\"f\")[..., np.newaxis]  # shape: (256, 1638, 1)\n",
    "        return img\n",
    "\n",
    "    def lazy_init(self, paths=None, labels=None, transform=None):\n",
    "        \"\"\"Reset Members\"\"\"\n",
    "        if paths is not None:\n",
    "            self.paths = paths\n",
    "        if labels is not None:\n",
    "            self.labels = labels\n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "\n",
    "\n",
    "class SetiAObsDataset(SetiSimpleDataset):\n",
    "    \"\"\"Use only on-target observation\"\"\"\n",
    "\n",
    "    def _read_cadence_array(self, path: Path):\n",
    "        \"\"\"Read cadence file and reshape\"\"\"\n",
    "        img = np.load(path)[[0, 2, 4]]  # shape: (3, 273, 256)\n",
    "        img = np.vstack(img)  # shape: (819, 256)\n",
    "        img = img.transpose(1, 0)  # shape: (256, 819)\n",
    "        img = img.astype(\"f\")[..., np.newaxis]  # shape: (256, 819, 1)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch = tp.Union[tp.Tuple[torch.Tensor], tp.Dict[str, torch.Tensor]]\n",
    "ModelOut = tp.Union[tp.Tuple[torch.Tensor], tp.Dict[str, torch.Tensor], torch.Tensor]\n",
    "\n",
    "\n",
    "class ROCAUC(nn.Module):\n",
    "    \"\"\"ROC AUC score\"\"\"\n",
    "\n",
    "    def __init__(self, average=\"macro\") -> None:\n",
    "        \"\"\"Initialize.\"\"\"\n",
    "        self.average = average\n",
    "        super(ROCAUC, self).__init__()\n",
    "\n",
    "    def forward(self, y, t) -> float:\n",
    "        \"\"\"Forward.\"\"\"\n",
    "        if isinstance(y, torch.Tensor):\n",
    "            y = y.detach().cpu().numpy()\n",
    "        if isinstance(t, torch.Tensor):\n",
    "            t = t.detach().cpu().numpy()\n",
    "\n",
    "        return roc_auc_score(t, y, average=self.average)\n",
    "\n",
    "\n",
    "def micro_average(\n",
    "    metric_func: nn.Module,\n",
    "    report_name: str, prefix=\"val\",\n",
    "    pred_index: int=-1, label_index: int=-1,\n",
    "    pred_key: str=\"logit\", label_key: str=\"target\",\n",
    ") -> tp.Callable:\n",
    "    \"\"\"Return Metric Wrapper for Simple Mean Metric\"\"\"\n",
    "    metric_sum = [0.]\n",
    "    n_examples = [0]\n",
    "    \n",
    "    def wrapper(batch: Batch, model_output: ModelOut, is_last_batch: bool):\n",
    "        \"\"\"Wrapping metric function for evaluation\"\"\"\n",
    "        if isinstance(batch, tuple): \n",
    "            t = batch[label_index]\n",
    "        elif isinstance(batch, dict):\n",
    "            t = batch[label_key]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        if isinstance(model_output, tuple):\n",
    "            y = model_output[pred_index]\n",
    "        elif isinstance(model_output, dict):\n",
    "            y = model_output[pred_key]\n",
    "        else:\n",
    "            y = model_output\n",
    "\n",
    "        metric = metric_func(y, t).item()\n",
    "        metric_sum[0] += metric * y.shape[0]\n",
    "        n_examples[0] += y.shape[0]\n",
    "\n",
    "        if is_last_batch:\n",
    "            final_metric = metric_sum[0] / n_examples[0]\n",
    "            ppe.reporting.report({f\"{prefix}/{report_name}\": final_metric})\n",
    "            # # reset state\n",
    "            metric_sum[0] = 0.\n",
    "            n_examples[0] = 0\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "def calc_across_all_batchs(\n",
    "    metric_func: nn.Module,\n",
    "    report_name: str, prefix=\"val\",\n",
    "    pred_index: int=-1, label_index: int=-1,\n",
    "    pred_key: str=\"logit\", label_key: str=\"target\",\n",
    ") -> tp.Callable:\n",
    "    \"\"\"\n",
    "    Return Metric Wrapper for Metrics caluculated on all data\n",
    "    \n",
    "    storing predictions and labels of evry batch, finally calculating metric on them.\n",
    "    \"\"\"\n",
    "    pred_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    def wrapper(batch: Batch, model_output: ModelOut, is_last_batch: bool):\n",
    "        \"\"\"Wrapping metric function for evaluation\"\"\"\n",
    "        if isinstance(batch, tuple):\n",
    "            t = batch[label_index]\n",
    "        elif isinstance(batch, dict):\n",
    "            t = batch[label_key]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        if isinstance(model_output, tuple):\n",
    "            y = model_output[pred_index]\n",
    "        elif isinstance(model_output, dict):\n",
    "            y = model_output[pred_key]\n",
    "        else:\n",
    "            y = model_output\n",
    "\n",
    "        pred_list.append(y.numpy())\n",
    "        label_list.append(t.numpy())\n",
    "\n",
    "        if is_last_batch:\n",
    "            pred = np.concatenate(pred_list, axis=0)\n",
    "            label = np.concatenate(label_list, axis=0)\n",
    "            final_metric = metric_func(pred, label)\n",
    "            ppe.reporting.report({f\"{prefix}/{report_name}\": final_metric})\n",
    "            # # reset state\n",
    "            pred_list[:] = []\n",
    "            label_list[:] = []\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_TYPES = {\n",
    "    # # utils\n",
    "    \"__len__\": lambda obj: len(obj),\n",
    "    \"method_call\": lambda obj, method: getattr(obj, method)(),\n",
    "\n",
    "    # # Dataset, DataLoader\n",
    "    \"SetiSimpleDataset\": SetiSimpleDataset,\n",
    "    \"SetiAObsDataset\": SetiAObsDataset,\n",
    "    \"DataLoader\": torch.utils.data.DataLoader,\n",
    "\n",
    "    # # Data Augmentation\n",
    "    \"Compose\": A.Compose, \"OneOf\": A.OneOf,\n",
    "    \"Resize\": A.Resize,\n",
    "    \"HorizontalFlip\": A.HorizontalFlip, \"VerticalFlip\": A.VerticalFlip,\n",
    "    \"ShiftScaleRotate\": A.ShiftScaleRotate,\n",
    "    \"RandomResizedCrop\": A.RandomResizedCrop,\n",
    "    \"Cutout\": A.Cutout,\n",
    "    \"RandomRotate90\": A.RandomRotate90,\n",
    "    \"RandomScale\":A.RandomScale,\n",
    "    \"ToTensorV2\": ToTensorV2,\n",
    "\n",
    "    # # Model\n",
    "    \"BasicImageModel\": enetv2,\n",
    "    \n",
    "    #BasicImageModel\n",
    "\n",
    "    # # Optimizer\n",
    "    \"AdamW\": optim.AdamW,\n",
    "    \"Ranger\": Ranger,\n",
    "\n",
    "    # # Scheduler\n",
    "    \"OneCycleLR\": lr_scheduler.OneCycleLR,\n",
    "\n",
    "    # # Loss,Metric\n",
    "    \"BCEWithLogitsLoss\": nn.BCEWithLogitsLoss,\n",
    "    \"ROCAUC\": ROCAUC,\n",
    "\n",
    "    # # Metric Wrapper\n",
    "    \"micro_average\": micro_average,\n",
    "    \"calc_across_all_batchs\": calc_across_all_batchs,\n",
    "\n",
    "    # # PPE Extensions\n",
    "    \"ExtensionsManager\": ppe.training.ExtensionsManager,\n",
    "\n",
    "    \"observe_lr\": ppe_exts.observe_lr,\n",
    "    \"LogReport\": ppe_exts.LogReport,\n",
    "    \"PlotReport\": ppe_exts.PlotReport,\n",
    "    \"PrintReport\": ppe_exts.PrintReport,\n",
    "    \"PrintReportNotebook\": ppe_exts.PrintReportNotebook,\n",
    "    \"ProgressBar\": ppe_exts.ProgressBar,\n",
    "    \"ProgressBarNotebook\": ppe_exts.ProgressBarNotebook,\n",
    "    \"snapshot\": ppe_exts.snapshot,\n",
    "    \"LRScheduler\": ppe_exts.LRScheduler, \n",
    "\n",
    "    \"MinValueTrigger\": ppe_triggers.MinValueTrigger,\n",
    "    \"MaxValueTrigger\": ppe_triggers.MaxValueTrigger,\n",
    "    \"EarlyStoppingTrigger\": ppe_triggers.EarlyStoppingTrigger,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_eval_cfg = yaml.safe_load(\n",
    "\"\"\"\n",
    "globals:\n",
    "  seed: 42\n",
    "  val_fold: null  # indicate when training\n",
    "  output_path: null # indicate when training\n",
    "  device: cuda:2\n",
    "  enable_amp: True\n",
    "  max_epoch: 20\n",
    "\n",
    "model:\n",
    "  type: BasicImageModel\n",
    "  dims_head: [null, 1]\n",
    "  base_name: tf_efficientnet_b6_ns\n",
    "  pretrained: False\n",
    "  in_channels: 1\n",
    "\n",
    "dataset:\n",
    "  height: 720\n",
    "  width: 720\n",
    "  mixup: {enabled: True, alpha: 0.6}\n",
    "  train:\n",
    "    type: SetiAObsDataset\n",
    "    paths: null  # set by lazy_init\n",
    "    labels: null  # set by lazy_init\n",
    "    transform:\n",
    "      type: Compose\n",
    "      transforms:\n",
    "        - {type: Resize, p: 1.0, height: \"@/dataset/height\", width: \"@/dataset/width\"}\n",
    "        - {type: HorizontalFlip, p: 0.4}\n",
    "        - {type: VerticalFlip, p: 0.4}\n",
    "        - {type: ShiftScaleRotate, p: 0.6, shift_limit: 0.2, scale_limit: 0.2,\n",
    "            rotate_limit: 20, border_mode: 0, value: 0, mask_value: 0}\n",
    "        - {type: RandomScale, p: 0.6, scale_limit: [-0.2, +0.2], interpolation : 1}\n",
    "        - {type: RandomRotate90, p: 0.4}\n",
    "        - {type: Cutout, p: 0.6, num_holes: 100, max_h_size: 2,\n",
    "            max_w_size: 2}\n",
    "        - {type: RandomResizedCrop, p: 1.0,\n",
    "            scale: [0.9, 1.0], height: \"@/dataset/height\", width: \"@/dataset/width\"}\n",
    "        - {type: ToTensorV2, always_apply: True}\n",
    "  val:\n",
    "    type: SetiAObsDataset\n",
    "    paths: null  # set by lazy_init\n",
    "    labels: null  # set by lazy_init\n",
    "    transform:\n",
    "      type: Compose\n",
    "      transforms:\n",
    "        - {type: Resize, p: 1.0, height: \"@/dataset/height\", width: \"@/dataset/width\"}\n",
    "        - {type: ToTensorV2, always_apply: True}  \n",
    "  test:\n",
    "    type: SetiAObsDataset\n",
    "    paths: null  # set by lazy_init\n",
    "    labels: null  # set by lazy_init\n",
    "    transform: \"@/dataset/val/transform\"\n",
    "\n",
    "loader:\n",
    "  train: {type: DataLoader, dataset: \"@/dataset/train\",\n",
    "    batch_size: 192, num_workers: 8, shuffle: True, pin_memory: True, drop_last: True}\n",
    "  val: {type: DataLoader, dataset: \"@/dataset/val\",\n",
    "    batch_size: 4, num_workers: 8, shuffle: False, pin_memory: True, drop_last: False}\n",
    "  test: {type: DataLoader, dataset: \"@/dataset/test\",\n",
    "    batch_size: 2, num_workers: 8, shuffle: False, pin_memory: True, drop_last: False}\n",
    "\n",
    "optimizer:\n",
    "  type: Ranger\n",
    "  params: {type: method_call, obj: \"@/model\", method: parameters}\n",
    "  lr: 5.0e-06\n",
    "  weight_decay: 1.0e-02\n",
    "\n",
    "scheduler:\n",
    "  type: OneCycleLR\n",
    "  optimizer: \"@/optimizer\"\n",
    "  epochs: \"@/globals/max_epoch\"\n",
    "  steps_per_epoch: {type: __len__, obj: \"@/loader/train\"}\n",
    "  max_lr: 1.0e-3\n",
    "  pct_start: 0.1\n",
    "  anneal_strategy: cos\n",
    "  div_factor: 1.0e+3\n",
    "  final_div_factor: 1.0e+3\n",
    "\n",
    "loss: {type: BCEWithLogitsLoss}\n",
    "\n",
    "eval:\n",
    "  - type: micro_average\n",
    "    metric_func: {type: BCEWithLogitsLoss}\n",
    "    report_name: loss\n",
    "  - type: calc_across_all_batchs\n",
    "    metric_func: {type: ROCAUC}\n",
    "    report_name: metric\n",
    "\n",
    "manager:\n",
    "  type: ExtensionsManager\n",
    "  models: \"@/model\"\n",
    "  optimizers: \"@/optimizer\"\n",
    "  max_epochs: \"@/globals/max_epoch\"\n",
    "  iters_per_epoch: {type: __len__, obj: \"@/loader/train\"}\n",
    "  out_dir: \"@/globals/output_path\"\n",
    "  # stop_trgiger: {type: EarlyStoppingTrigger,\n",
    "  #   monitor: val/metric, mode: max, patience: 5, verbose: True,\n",
    "  #   check_trigger: [1, epoch], max_trigger: [\"@/globals/max_epoch\", epoch]}\n",
    "\n",
    "extensions:\n",
    "  # # log\n",
    "  - {type: observe_lr, optimizer: \"@/optimizer\"}\n",
    "  - {type: LogReport}\n",
    "  - {type: PlotReport, y_keys: lr, x_key: epoch, filename: lr.png}\n",
    "  - {type: PlotReport, y_keys: [train/loss, val/loss], x_key: epoch, filename: loss.png}\n",
    "  - {type: PlotReport, y_keys: val/metric, x_key: epoch, filename: metric.png}\n",
    "  - {type: PrintReport, entries: [\n",
    "      epoch, iteration, lr, train/loss, val/loss, val/metric, elapsed_time]}\n",
    "  - {type: ProgressBarNotebook, update_interval: 20}\n",
    "  # snapshot\n",
    "  - extension: {type: snapshot, target: \"@/model\", filename: \"snapshot_by_metric_epoch_{.epoch}.pth\"}\n",
    "    trigger: {type: MaxValueTrigger, key: \"val/metric\", trigger: [1, epoch]}\n",
    "  # # lr scheduler\n",
    "  - {type: LRScheduler, scheduler: \"@/scheduler\", trigger: [1,  iteration]}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed: int = 42, deterministic: bool = False):\n",
    "    \"\"\"Set seeds\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = deterministic  # type: ignore\n",
    "\n",
    "\n",
    "def to_device(\n",
    "    tensors: tp.Union[tp.Tuple[torch.Tensor], tp.Dict[str, torch.Tensor]],\n",
    "    device: torch.device, *args, **kwargs\n",
    "):\n",
    "    if isinstance(tensors, tuple):\n",
    "        return (t.to(device, *args, **kwargs) for t in tensors)\n",
    "    elif isinstance(tensors, dict):\n",
    "        return {\n",
    "            k: t.to(device, *args, **kwargs) for k, t in tensors.items()}\n",
    "    else:\n",
    "        return tensors.to(device, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path_label(cfg: Config, train_all: pd.DataFrame):\n",
    "    \"\"\"Get file path and target info.\"\"\"\n",
    "    use_fold = cfg[\"/globals/val_fold\"]\n",
    "    \n",
    "    #train_all_new = pd.concat([train_all,pesudo],axis =0).reset_index(drop=True) \n",
    "\n",
    "    train_df = train_all[train_all[\"fold\"] != use_fold]\n",
    "    val_df = train_all[train_all[\"fold\"] == use_fold]\n",
    "    \n",
    "    train_paths = [TRAIN + f\"/{img_id[0]}/{img_id}.npy\" for img_id in train_df[\"id\"].values]\n",
    "    train_labels = train_df[CLASSES].values.astype(\"f\")\n",
    "    \n",
    "    #changes for pesudo labels training\n",
    "    ########################################################################\n",
    "    #pesudo_paths = [TEST + f\"/{img_id[0]}/{img_id}.npy\" for img_id in pesudo[\"id\"].values]\n",
    "    #pesudo_labels = pesudo[CLASSES].values.astype(\"f\")\n",
    "    \n",
    "    #combined_paths = train_paths + pesudo_paths\n",
    "    #combined_lables = np.concatenate((train_labels, pesudo_labels))\n",
    "    ############################################################################\n",
    "    \n",
    "    train_path_label = {\n",
    "        \"paths\": train_paths,\n",
    "        \"labels\": train_labels}\n",
    "    val_path_label = {\n",
    "        \"paths\": [TRAIN + f\"/{img_id[0]}/{img_id}.npy\" for img_id in val_df[\"id\"].values],\n",
    "        \"labels\": val_df[CLASSES].values.astype(\"f\")\n",
    "    }\n",
    "    return train_path_label, val_path_label\n",
    "\n",
    "\n",
    "def get_eval_func(cfg, model, device):\n",
    "    \n",
    "    def eval_func(**batch):\n",
    "        \"\"\"Run evaliation for val or test. This function is applied to each batch.\"\"\"\n",
    "        batch = to_device(batch, device)\n",
    "        x = batch[\"image\"]\n",
    "        with amp.autocast(cfg[\"/globals/enable_amp\"]): \n",
    "            y = model(x)\n",
    "        return y.detach().cpu().to(torch.float32)  # input of metrics\n",
    "\n",
    "    return eval_func\n",
    "\n",
    "\n",
    "def mixup_data(use_mixup, x, t, alpha=1.0, use_cuda=True):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "    if not use_mixup:\n",
    "        return x, t, None, None\n",
    "    \n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    t_a, t_b = t, t[index]\n",
    "    return mixed_x, t_a, t_b, lam\n",
    "\n",
    "\n",
    "def get_criterion(use_mixup, loss_func):\n",
    "\n",
    "    def mixup_criterion(pred, t_a, t_b, lam):\n",
    "        return lam * loss_func(pred, t_a) + (1 - lam) * loss_func(pred, t_b)\n",
    "\n",
    "    def single_criterion(pred, t_a, t_b, lam):\n",
    "        return loss_func(pred, t_a)\n",
    "    \n",
    "    if use_mixup:\n",
    "        return mixup_criterion\n",
    "    else:\n",
    "        return single_criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_fold(cfg, train_all):\n",
    "    \"\"\"Main\"\"\"\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    set_random_seed(cfg[\"/globals/seed\"], True)\n",
    "    device = torch.device(cfg[\"/globals/device\"])\n",
    "    use_fold = cfg[\"/globals/val_fold\"]\n",
    "    \n",
    "    train_path_label, val_path_label = get_path_label(cfg, train_all)\n",
    "    print(\"train: {}, val: {}\".format(len(train_path_label[\"paths\"]), len(val_path_label[\"paths\"])))\n",
    "   \n",
    "    cfg[\"/dataset/train\"].lazy_init(**train_path_label)\n",
    "    cfg[\"/dataset/val\"].lazy_init(**val_path_label)\n",
    "    train_loader = cfg[\"/loader/train\"]\n",
    "    val_loader = cfg[\"/loader/val\"]\n",
    "\n",
    "    model = cfg[\"/model\"]\n",
    "    # pretrained model load\n",
    "    #################################################################\n",
    "    #model_path = f\"./v1_1_old_dataset/eca_nfnet_l0_ranger_amp_512.pth\"\n",
    "    model_path = f\"./eca_nfnet_l0_Ranger_amp_pseudo_720_specs_finetune_780/best_metric_model_fold{use_fold}.pth\"\n",
    "    state_dict = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    print('Successfully Loaded pretrained Model ',model_path)\n",
    "    ##################################################################\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Let's use %d GPUs! \\n\" % (torch.cuda.device_count()))\n",
    "        model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "    optimizer = cfg[\"/optimizer\"]\n",
    "    loss_func = cfg[\"/loss\"]\n",
    "    loss_func.to(device)\n",
    "    \n",
    "    manager = cfg[\"/manager\"]\n",
    "    for ext in cfg[\"/extensions\"]:\n",
    "        if isinstance(ext, dict):\n",
    "            manager.extend(**ext)\n",
    "        else:\n",
    "            manager.extend(ext)\n",
    "\n",
    "    evaluator = ppe_exts.Evaluator(\n",
    "        val_loader, model, eval_func=get_eval_func(cfg, model, device),\n",
    "        metrics=cfg[\"/eval\"], progress_bar=False)\n",
    "    manager.extend(evaluator, trigger=(1, \"epoch\"))\n",
    "\n",
    "    use_amp = cfg[\"/globals/enable_amp\"]\n",
    "    scaler = amp.GradScaler(enabled=use_amp)\n",
    "    use_mixup = cfg[\"/dataset/mixup/enabled\"]\n",
    "    mixup_alpha = cfg[\"/dataset/mixup/alpha\"]\n",
    "    \n",
    "    while not manager.stop_trigger:\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            with manager.run_iteration():\n",
    "                batch = to_device(batch, device)\n",
    "                x, t = batch[\"image\"], batch[\"target\"]\n",
    "                # # for mixup\n",
    "                mixed_x, t_a, t_b, lam = mixup_data(use_mixup, x, t, mixup_alpha)\n",
    "                criterion = get_criterion(use_mixup, loss_func)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                with amp.autocast(use_amp):\n",
    "                    y = model(mixed_x)\n",
    "                    loss = criterion(y, t_a, t_b, lam)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                \n",
    "                ppe.reporting.report({'train/loss': loss.item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_eval_cfg_list = []\n",
    "for fold_id in FOLDS:\n",
    "   tmp_cfg = copy.deepcopy(pre_eval_cfg)\n",
    "   tmp_cfg[\"globals\"][\"val_fold\"] = fold_id\n",
    "   tmp_cfg[\"globals\"][\"output_path\"] = TMP + f\"/fold{fold_id}\"\n",
    "   pre_eval_cfg_list.append(tmp_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./tf_efficientnet_b6_ns_new_pretrained_v1/'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pre_eval_cfg in pre_eval_cfg_list:\n",
    "#     cfg = Config(pre_eval_cfg, types=CONFIG_TYPES)\n",
    "#     print(f\"\\nfold:\", cfg[\"/globals/val_fold\"])\n",
    "#     train_one_fold(cfg, train)\n",
    "#     del cfg\n",
    "#     torch.cuda.empty_cache()\n",
    "#     gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp_dir_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './tf_efficientnet_b6_ns_new_pretrained_v1//fold1/config.yml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-6bf26ef615b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#shutil.copytree(exp_dir_path, f\"./final_models/fold{fold_id}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTMP\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34mf\"/fold{fold_id}/config.yml\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_eval_cfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './tf_efficientnet_b6_ns_new_pretrained_v1//fold1/config.yml'"
     ]
    }
   ],
   "source": [
    "best_log_list = []\n",
    "for pre_eval_cfg, fold_id in zip(pre_eval_cfg_list, FOLDS):\n",
    "    exp_dir_path = TMP + f\"fold{fold_id}\"\n",
    "    #log = pd.read_json(exp_dir_path + \"/log\")\n",
    "    #best_log = log.iloc[[log[\"val/metric\"].idxmax()],]\n",
    "    #best_epoch = best_log.epoch.values[0]\n",
    "    #best_log_list.append(best_log)\n",
    "    \n",
    "    #best_model_path = exp_dir_path + f\"/snapshot_by_metric_epoch_{best_epoch}.pth\"\n",
    "    #copy_to = TMP + f\"/best_metric_model_fold{fold_id}.pth\"\n",
    "    #shutil.copy(best_model_path, copy_to)\n",
    "    \n",
    "    #for p in exp_dir_path.glob(\"*.pth\"):\n",
    "    #    p.unlink()\n",
    "    \n",
    "    #shutil.copytree(exp_dir_path, f\"./final_models/fold{fold_id}\")\n",
    "    \n",
    "    with open(TMP+f\"/fold{fold_id}/config.yml\", \"w\") as fw:\n",
    "        yaml.dump(pre_eval_cfg, fw)\n",
    "    \n",
    "pd.concat(best_log_list, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def run_inference_loop(cfg, model, loader, device):\n",
    "#    model.to(device)\n",
    "#    model.eval()\n",
    "#    pred_list = []\n",
    "#    with torch.no_grad():\n",
    "#        for batch in tqdm(loader):\n",
    "#            x = to_device(batch[\"image\"], device)\n",
    "#            y = model(x)\n",
    "#            pred_list.append(y.sigmoid().detach().cpu().numpy())\n",
    "#        \n",
    "#    pred_arr = np.concatenate(pred_list)\n",
    "#    del pred_list\n",
    "#    return pred_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_loop(cfg, model, loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    pred_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader):\n",
    "            x = to_device(batch[\"image\"], device)\n",
    "            a = len(x)\n",
    "            x1 = x\n",
    "            x2 = x.flip(-1)\n",
    "            y1 = model(x1)\n",
    "            y2 = model(x2)\n",
    "            y = (y1+y2)/2\n",
    "\n",
    "            pred_list.append(y.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    pred_arr = np.concatenate(pred_list)\n",
    "    del pred_list\n",
    "    return pred_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Model Params ######\n",
    "model_params = dict(backbone='tf_efficientnet_b6_ns',\n",
    "                    in_channels=1,\n",
    "                    out_dim=1,\n",
    "                    pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./tf_efficientnet_b6_ns_new_pretrained_v1/'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold 0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c86b453f71654fc9938ee2aef44475f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb9aca39da244bb8295441add13a3df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19998.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_arr = train[CLASSES].values\n",
    "oof_pred_arr = np.zeros((len(train), N_CLASSES))\n",
    "score_list = []\n",
    "test_pred_arr = np.zeros((N_FOLDS, len(smpl_sub), N_CLASSES))\n",
    "test_path_label = {\n",
    "    #\"paths\": [f\"./test/{img_id[0]}/{img_id}.npy\" for img_id in smpl_sub[\"id\"].values],\n",
    "    \"paths\": [TEST + f\"/{img_id[0]}/{img_id}.npy\" for img_id in smpl_sub[\"id\"].values],\n",
    "    \"labels\": smpl_sub[CLASSES].values.astype(\"f\")\n",
    "}\n",
    "\n",
    "for fold_id in range(N_FOLDS):\n",
    "    print(f\"[fold {fold_id}]\")\n",
    "    tmp_dir = Path(TMP+f\"/fold{fold_id}\")\n",
    "    with open(tmp_dir / \"config.yml\", \"r\") as fr:\n",
    "        cfg = Config(yaml.safe_load(fr), types=CONFIG_TYPES)\n",
    "    device = torch.device(cfg[\"/globals/device\"])\n",
    "    val_idx = train.query(\"fold == @fold_id\").index.values\n",
    "\n",
    "    # # get_dataloader\n",
    "    _, val_path_label = get_path_label(cfg, train)\n",
    "    cfg[\"/dataset/val\"].lazy_init(**val_path_label)\n",
    "    cfg[\"/dataset/test\"].lazy_init(**test_path_label)\n",
    "    val_loader = cfg[\"/loader/val\"]\n",
    "    test_loader = cfg[\"/loader/test\"]\n",
    "    \n",
    "    # # get model\n",
    "    model_path = TMP+f\"model_tf_efficientnet_b6_ns_IMG_SIZE_640_fold{fold_id}.bin\"\n",
    "    #model = cfg[\"/model\"]\n",
    "    model = enetv2(**model_params)\n",
    "    model = nn.DataParallel(model, device_ids=[2])\n",
    "    state_dict = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    #model.load_state_dict(state_dict.module.state_dict())\n",
    "    \n",
    "    # # inference\n",
    "    val_pred = run_inference_loop(cfg, model, val_loader, device)\n",
    "    val_score = roc_auc_score(label_arr[val_idx], val_pred)\n",
    "    oof_pred_arr[val_idx] = val_pred\n",
    "    score_list.append([fold_id, val_score])\n",
    "    \n",
    "    test_pred_arr[fold_id] = run_inference_loop(cfg, model, test_loader, device)\n",
    "    \n",
    "    del cfg, val_idx, val_path_label\n",
    "    del model, val_loader, test_loader\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    print(f\"val score: {val_score:.4f}\")\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.890237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.893627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.880002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.877085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.885006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>oof</td>\n",
       "      <td>0.884816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fold    metric\n",
       "0    0  0.890237\n",
       "1    1  0.893627\n",
       "2    2  0.880002\n",
       "3    3  0.877085\n",
       "4    4  0.885006\n",
       "5  oof  0.884816"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_score = roc_auc_score(label_arr, oof_pred_arr)\n",
    "score_list.append([\"oof\", oof_score])\n",
    "pd.DataFrame(score_list, columns=[\"fold\", \"metric\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_df = train.copy()\n",
    "oof_df[CLASSES] = oof_pred_arr\n",
    "oof_df.to_csv(TMP+\"/oof_prediction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = smpl_sub.copy()\n",
    "sub_df[CLASSES] = test_pred_arr.mean(axis=0)\n",
    "sub_df.to_csv(TMP+\"/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bf832cae9ff1</td>\n",
       "      <td>0.040658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c74cc71a1140</td>\n",
       "      <td>0.060437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000f5f9851161d3</td>\n",
       "      <td>0.049354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000f7499e95aba6</td>\n",
       "      <td>0.101618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00133ce6ec257f9</td>\n",
       "      <td>0.045736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id    target\n",
       "0  000bf832cae9ff1  0.040658\n",
       "1  000c74cc71a1140  0.060437\n",
       "2  000f5f9851161d3  0.049354\n",
       "3  000f7499e95aba6  0.101618\n",
       "4  00133ce6ec257f9  0.045736"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
